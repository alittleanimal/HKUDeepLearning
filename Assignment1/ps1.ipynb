{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optimum-behavior",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02ec15742eac7a752e643a0feb243be8",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Image Classification of Cifar10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-character",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03af55d15e6fe43e22d5ac981485fe65",
     "grade": false,
     "grade_id": "introduction",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this assignment, we will train several image classification models using the [CIFAR-10 dataset](https://keras.io/api/datasets/cifar10/). The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The training images contain exactly 5000 images from each class and the test images contain exactly 1000 randomly-selected images from each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-vegetarian",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "146c3b07f118160996c6c7d2a449f539",
     "grade": false,
     "grade_id": "cell-bf016d6d8ff9f65b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Important Notes\n",
    "* requirements:\n",
    "  * python 3.6\n",
    "  * tensorflow 2.0.0 (or tensorflow-gpu 2.0.0), h5py 2.10.0, scipy >= 1.5.4, pandas 1.1.5, numpy 1.19, matplotlib\n",
    "  * to install a package like tensorflow with specific version 2.0.0, use <strong> pip3 install tensorflow==2.0.0 </strong>\n",
    "* You are suggested to execute code we provided in order. You can add cells to do experiments, but <strong>DO NOT change code we provided unless it is a function that you need to complete</strong>. In each graded function cell, you should replace \"raise NotImplementedError()\" under \"# YOUR CODE HERE\" by your own answer. For some graded functions, we have already provided some test cases for you. Passing these test cases will guarantee that you can at least get some scores. We have some hidden tests. So passing all tests in this notebook doesn't mean you can get all scores. <strong> Do Not Delete any cell we provided, it may lead to scroing error for some hidden test cases. </strong> If you accidently deleted some graded function cells or test cells, you should download this assignment again. <strong> Adding a new cell and pasting deleted content won't work in this case. </strong>\n",
    "* Only funtions specified in the Graded Function part will be graded. Other parts will be ignored during grading.\n",
    "* <strong> Rename this ps1.ipynb file as <your_hku_student_id>.ipynb to submit </strong>. For example, if your student id is 1234567890, then your should rename ps1.ipynb as 1234567890.ipynb.\n",
    "* GPU is not required. But if you want to run the training code faster, you can use GPU. [How to use HKU GPU](https://www.cs.hku.hk/gpu-farm/home). Another option is to use [google colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-thursday",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cac77f6f980abb4b94d676380576b03",
     "grade": false,
     "grade_id": "cell-75a72d11d23cfb4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Sections\n",
    "* [Data Process](#dp)\n",
    "* [MLP Classifier](#mlp)\n",
    "* [CNN Classifier](#cnn)\n",
    "* [Transfer Learning](#tl)\n",
    "* [Data Augmentation](#da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-consequence",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "784110bc6d126d1bdf6962a866b66146",
     "grade": false,
     "grade_id": "cell-a161f46ed06a3af1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-knitting",
   "metadata": {},
   "source": [
    "<a name='dp'></a>\n",
    "# 1. Data Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-defense",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2aac36bbd70974b8148fcbacb9443f3",
     "grade": false,
     "grade_id": "load_data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Graded Function:\n",
    "Complete the load_data function below. You should:\n",
    "* load cifar10 dataset using the tf.keras.datasets api (check [this link](https://keras.io/api/datasets/cifar10/))\n",
    "* rescale pixel values of x_train, x_test to range \\[0,1\\] by dividing them by 255.0 \n",
    "* reshape y_train, y_test to shape (-1,)\n",
    "* return the dataset in this format: (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-pakistan",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aed969d84211a3a57c8ef1ef17a55b9f",
     "grade": false,
     "grade_id": "cell-97f8e73630646669",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"load cifar10 dataset using the tf.keras.datasets api and \n",
    "    return the loaded data as two tuples: (x_train, y_train), (x_test, y_test)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-equilibrium",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d84991ee81d69a15cca6867303c157d7",
     "grade": true,
     "grade_id": "cell-297fed09a2ea97c2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "(test_x_train, test_y_train), (test_x_test, test_y_test) = load_data()\n",
    "assert test_x_train.shape == (50000, 32, 32, 3)\n",
    "assert test_y_train.shape == (50000,)\n",
    "assert test_x_test.shape == (10000, 32, 32, 3)\n",
    "assert test_y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-matthew",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdd1b9869b84ce9085cbb8f71785a9bb",
     "grade": true,
     "grade_id": "cell-1ae3e5a738197831",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains a hiddent test, don't delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-income",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16affe67e51713735542497696df6dfd",
     "grade": false,
     "grade_id": "cell-508069c51b35a92d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# load the data using load_data function\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "# show the first five train images and its label\n",
    "classes = [\"airplane\",\"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "          \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "fig, axs = plt.subplots(1,5, figsize=(15,15))\n",
    "for i in range(5):\n",
    "    axs[i].imshow(x_train[i])\n",
    "    axs[i].set_title(classes[y_train[i]])\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-detail",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2472dcc8c38b6d3d01d44e2e2545042e",
     "grade": false,
     "grade_id": "cell-4a8233221b37dcc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Graded Function:\n",
    "You will complete the create_dataset function below. This function will take five arguments (images, labels, batch_size, buffer_size, seed). Later on you will pass in (x_train, y_train, augment_map) and (x_test, y_test, augment_map) to create datasets. You should create a dataset with the following steps:\n",
    "* first create a tf.data.Dataset object using tf.data.Dataset.from_tensor_slices method. Each element of the resulting dataset should be a tuple (image, label)\n",
    "* batch the dataset with batch size set to the batch_size argument\n",
    "* shuffle the dataset with shuffle buffer size set to buffer_size argument, shuffle seed set to seed argument and set reshuffle_each_iteration to False\n",
    "* return the dataset you created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-wings",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16069f01647c3c5e917e805ed6a9ef62",
     "grade": false,
     "grade_id": "cell-7921dd9e4356073b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(images, labels, batch_size, buffer_size=10_000, seed=None):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-eugene",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a098bfbec3970d6c3c797d36d2c667cd",
     "grade": true,
     "grade_id": "cell-5e646e842306ee85",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "(test_x_train, test_y_train), (test_x_test, test_y_test) = cifar10.load_data()\n",
    "dataset_1 = create_dataset(test_x_test, test_y_test, batch_size=32, seed=200)\n",
    "assert isinstance(dataset_1, tf.data.Dataset)\n",
    "example = next(iter(dataset_1))\n",
    "example_2 = next(iter(dataset_1))\n",
    "assert example[0].shape == (32,32,32,3)\n",
    "assert example[1].shape == (32,1)\n",
    "assert example_2[0].shape == (32,32,32,3)\n",
    "assert example_2[1].shape == (32,1)\n",
    "del test_x_train\n",
    "del test_y_train\n",
    "del test_x_test\n",
    "del test_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-house",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcd0c3e58ddf70d9f3d3fe924991cb9b",
     "grade": true,
     "grade_id": "cell-3179a91c879b3cb6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains a hiddent test, don't delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-lindsay",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fa3d57cc9847031fd1d57023548907e",
     "grade": false,
     "grade_id": "cell-5914d434c0416418",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create train and test datasets\n",
    "train_dataset = create_dataset(x_train, y_train, batch_size=32)\n",
    "test_dataset = create_dataset(x_test, y_test, batch_size=32)\n",
    "print(train_dataset.element_spec)\n",
    "print(test_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-direction",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30b58b23f177841aa5676abea54272b2",
     "grade": false,
     "grade_id": "cell-b554ce91618e3daa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a name='mlp'></a>\n",
    "# Graded Function:\n",
    "## 2. MLP neural network classifier\n",
    "Complete the build_mlp_model function below. The following requirements must be satisfied:\n",
    "* Build a MLP classifier model using the Sequential API. Your model should use only Flatten and Dense layers, with the final layer having a 10-way softmax output. \n",
    "* the paramter units is a list of integers and input_shape is a list or a tuple of integers.\n",
    "* you should use the tf.keras.models.Sequential api.\n",
    "* the first layer is a Flatten layer, you should set the input shape of this layer to the input_shape parameter of the function\n",
    "* the first layer is followed by len(units) dense layers. Intergers in the units list specify the number of units in these Dense layers (one by one). All these layers have ReLU activation function\n",
    "* then a final Dense layer is followed. This final dense layer has 10 units. A softmax activation function is used in this layer.\n",
    "* return the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-creativity",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25768b9d374d415c530ce2bc9d62979b",
     "grade": false,
     "grade_id": "cell-b66968fd0f156c40",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_mlp_model(units, input_shape):\n",
    "    model = Sequential()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-logan",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02d9452dea62bbc8595e81bcdc75e961",
     "grade": true,
     "grade_id": "cell-3242110d64a75410",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_units = [32]\n",
    "test_shape = [16, 16]\n",
    "test_model = build_mlp_model(test_units, test_shape)\n",
    "assert isinstance(test_model, tf.keras.models.Model)\n",
    "assert len(test_model.layers) == len(test_units) + 2\n",
    "assert test_model.layers[0].input_shape == (None, 16, 16)\n",
    "assert isinstance(test_model.layers[0], Flatten)\n",
    "config = test_model.layers[1].get_config()\n",
    "assert isinstance(test_model.layers[1], Dense)\n",
    "assert config['activation'] == 'relu'\n",
    "assert config['units'] == test_units[0]\n",
    "assert isinstance(test_model.layers[-1], Dense)\n",
    "config = test_model.layers[-1].get_config()\n",
    "assert isinstance(test_model.layers[-1], Dense)\n",
    "assert config['activation'] == 'softmax'\n",
    "assert config['units'] == 10\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-intent",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05ea50fef314058d646d2107eadb8cef",
     "grade": true,
     "grade_id": "cell-f86159b994adcf94",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains a hiddent test, don't delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-information",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1a3c4b6abf17bc63544122c6526fa07",
     "grade": false,
     "grade_id": "cell-ca4c7576bab2036f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create model and print out the model summary\n",
    "# units = [64,32]\n",
    "units = [64,32, 32]\n",
    "mlp_model = build_mlp_model(units, x_train.shape[1:])\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-architect",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f8b720e07b80538533a905766209286",
     "grade": false,
     "grade_id": "cell-a365af1538ac3bc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Graded Function:\n",
    "Complete the compile_model function below. Complie the model using the compile method of tf.keras.Model class:\n",
    "* use the adam optimizer with default parameters\n",
    "* use the sparse categorical crossentropy loss\n",
    "* use only the accuracy metric\n",
    "* this function shouldn't return anything (the model passed in will keep all the settings you compiled in this function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-czech",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc71467ec04e3ad654b47cb89ee9f442",
     "grade": false,
     "grade_id": "cell-87d0e04a58f356a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-panama",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37730a73c5aa2ac2e658fa79929ae359",
     "grade": false,
     "grade_id": "cell-798a4acf2b6e552c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compile the multi layer perceptron model\n",
    "compile_model(mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-genesis",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "288d796c6dd074c7ccb2151e9075de46",
     "grade": true,
     "grade_id": "cell-f7ce6ff6f6bd668f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_model = Sequential([Dense(100),\n",
    "                        Dense(2, activation='softmax')])\n",
    "compile_model(test_model)\n",
    "assert isinstance(test_model.optimizer, tf.keras.optimizers.Adam)\n",
    "assert hasattr(test_model, 'loss')\n",
    "assert test_model.loss == 'sparse_categorical_crossentropy'\n",
    "assert ['accuracy'] == test_model._compile_metrics\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-straight",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55291fc4efcdf36019cb9700630722a9",
     "grade": false,
     "grade_id": "cell-7d801b7ce289595e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train mlp model\n",
    "early_stop = EarlyStopping(patience=5, monitor='val_accuracy')\n",
    "history = mlp_model.fit(train_dataset, epochs=30, validation_data=test_dataset, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-feedback",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e181e4aebf0509ca6814cf9d2fa446a5",
     "grade": false,
     "grade_id": "cell-1e339267cf214ef9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create loss, accuracy dataframe\n",
    "df = pd.DataFrame(history.history)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-dayton",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4bb6df2885aa2897bf69e108c029bb8",
     "grade": false,
     "grade_id": "cell-2401e3f55f31ca20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot loss and accuracy against epoch\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8,3.5))\n",
    "df.plot(y=['loss', 'val_loss'], ax=axes[0], title='loss vs epcoh')\n",
    "df.plot(y=['accuracy', 'val_accuracy'], ax=axes[1], title='accuracy vs epoch')\n",
    "axes[0].set_xlabel('epoch')\n",
    "axes[0].set_ylabel('loss')\n",
    "axes[1].set_xlabel('epoch')\n",
    "axes[1].set_ylabel('accuracy')\n",
    "plt.subplots_adjust(wspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-firewall",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5347fad3861239b70ea23a272ff3f6e7",
     "grade": false,
     "grade_id": "cell-c07c3013d8f8d74e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the model on the test set\n",
    "mlp_model.evaluate(test_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-calvin",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3474531cc90298ef03204b307d438c67",
     "grade": false,
     "grade_id": "cell-1a5e805c1e5bdc7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a name='cnn'></a>\n",
    "# Graded Function:\n",
    "## 3. CNN neural network classifier\n",
    "Complete the build_cnn_model below using the Sequential API. You should:\n",
    "* Build a CNN classifier model using the Sequential API. Your model should use the Conv2D, MaxPool2D, BatchNormalization, Flatten, Dense and Dropout layers. The final layer should again have a 10-way softmax output. \n",
    "* the first layer is a Conv2D layer with 16 filters, (3,3) kernel size, ReLU activation, 'SAME' padding, and input_shape set to be input_shape parameter of the function\n",
    "* then a MaxPool2D layer with pool size (2,2)\n",
    "* then a Dropout layer with drop out rate set to be dropout_rate parameter of the function\n",
    "* then a Conv2D layer with 8 filters, (3,3) kernel size, ReLU activation, 'SAME' padding\n",
    "* then a MaxPool2D layer with pool size (2,2)\n",
    "* then a Dropout layer with drop out rate set to be dropout_rate parameter of the function\n",
    "* then a Flatten layer\n",
    "* then a Dense layer with 64 units and ReLU activation\n",
    "* then a BatchNormalization layer\n",
    "* then a Dropout layer with drop out rate set to be dropout_rate parameter of the function\n",
    "* then a Dense layer with 32 units and ReLU activation\n",
    "* then a BatchNormalization layer\n",
    "* then a Dropout layer with drop out rate set to be dropout_rate parameter of the function\n",
    "* then a final dense layer with 10 units and softmax activation function\n",
    "* return the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-parish",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32d975e6b592dd7d882615f251dae99c",
     "grade": false,
     "grade_id": "cell-ce44f0d360354335",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape, dropout_rate):\n",
    "    model = Sequential()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-leonard",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93b4ed4afcc5377d3865e45b33490cf3",
     "grade": true,
     "grade_id": "cell-b8a0637dfe47e2db",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_model = build_cnn_model((8,8, 1), 0.1)\n",
    "assert isinstance(test_model, tf.keras.models.Model)\n",
    "assert len(test_model.layers) == 14\n",
    "layer_num = 0\n",
    "assert isinstance(test_model.layers[layer_num], Conv2D)\n",
    "config = test_model.layers[layer_num].get_config()\n",
    "assert config['filters'] == 16\n",
    "assert config['kernel_size'] == (3,3)\n",
    "assert config['padding'] == 'same'\n",
    "assert config['batch_input_shape'] == (None, 8, 8, 1)\n",
    "assert config['activation'] == 'relu'\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-touch",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "426fce666ca785a99197f82f3a51b6b6",
     "grade": true,
     "grade_id": "cell-81e6f0024c005221",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains a hiddent test, don't delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-donor",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1783fffab04798f86c3e228d4298a7c",
     "grade": false,
     "grade_id": "cell-22f594e0ab7ce05d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create cnn model and view summary\n",
    "cnn_model = build_cnn_model(x_train.shape[1:], 0.1)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-venue",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3b406579b067ba85df93c7902d85319",
     "grade": false,
     "grade_id": "cell-bc1b8b9d2ed6d617",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compile and training model\n",
    "compile_model(cnn_model)\n",
    "early_stop = EarlyStopping(patience=4, monitor='val_accuracy')\n",
    "cnn_history = cnn_model.fit(train_dataset, epochs=30, validation_data=test_dataset, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-protocol",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1afa58f529ffd00003fdf8d8b058d1f",
     "grade": false,
     "grade_id": "cell-1d057f59e1a38661",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cnn_history.history)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-election",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5750345e97cc177da1d6ff06ccf76d69",
     "grade": false,
     "grade_id": "cell-559ecfddad6301df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot loss and accuracy against epoch\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8,3.5))\n",
    "df.plot(y=['loss', 'val_loss'], ax=axes[0], title='loss vs epcoh')\n",
    "df.plot(y=['accuracy', 'val_accuracy'], ax=axes[1], title='accuracy vs epoch')\n",
    "axes[0].set_xlabel('epoch')\n",
    "axes[0].set_ylabel('loss')\n",
    "axes[1].set_xlabel('epoch')\n",
    "axes[1].set_ylabel('accuracy')\n",
    "plt.subplots_adjust(wspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-thing",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35e3f52dad1c083bbc5fa3c02c487740",
     "grade": false,
     "grade_id": "cell-7cd32a108479f659",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the model on the test set\n",
    "cnn_model.evaluate(test_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-sierra",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1eb984a2c9d3d01dd402ca2bb5645759",
     "grade": false,
     "grade_id": "cell-4c6333290879fccf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see that our cnn model improved the accuracy a lot even though our cnn model has much less parameters than the mlp model. Model architecture really matters in Deep Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-thunder",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b53bff909280f43f12bfe0302acf6c8b",
     "grade": false,
     "grade_id": "cell-5b309cb9b406077a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Model Predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-consensus",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4feb6bef40944aebb7f4a4b7202bcc9",
     "grade": false,
     "grade_id": "cell-5c0b87abf1d52f61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# mlp and cnn predictions\n",
    "rand_idx = np.random.choice(range(x_test.shape[0]), size=5)\n",
    "fig, axs = plt.subplots(5, 3,figsize=(15,15))\n",
    "for i in range(5):\n",
    "    axs[i][0].imshow(x_test[rand_idx[i], :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "    axs[i][0].set_title(classes[y_test[rand_idx[i]]])\n",
    "    axs[i][0].set_xticks([]) \n",
    "    axs[i][0].set_yticks([]) \n",
    "    probs = mlp_model.predict(x_test[rand_idx[i]][np.newaxis, ...])[0]\n",
    "    prediction = np.argmax(probs)\n",
    "    axs[i][1].bar(range(1,11), probs)\n",
    "    axs[i][1].set_xticks([i for i in range(0, 10)]) \n",
    "    axs[i][1].set_title('mlp prediciton {}'.format(classes[prediction]))\n",
    "    probs = cnn_model.predict(x_test[rand_idx[i]][np.newaxis, ...])[0]\n",
    "    prediction = np.argmax(probs)\n",
    "    axs[i][2].bar(range(1,11), probs)\n",
    "    axs[i][2].set_xticks([i for i in range(0, 10)]) \n",
    "    axs[i][2].set_title('cnn prediciton {}'.format(classes[prediction]))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-thousand",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df72d846b2143c62731269b02d8282e0",
     "grade": false,
     "grade_id": "cell-fccc43d135c52418",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a name='tl'></a>\n",
    "## Transfer Learning\n",
    "Transfer learning is very popular and powerful in computer vision. When you don't have too much data and you still want to a good model, you may resort to transfer learning.\n",
    "We will use the pre-trained MobileNet V2 model, available to download from [Keras Applications](https://keras.io/applications/#mobilenetv2).\n",
    "We will remove the final layer of the network and replace it with new, untrained classifier layers for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-philadelphia",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49bec3b4c6546d97fd4215bcf166302d",
     "grade": false,
     "grade_id": "cell-bd6203944d069699",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get the body of EfficiekerasNetB1\n",
    "def get_ENB1_body():\n",
    "    pretrained_model = tf.keras.applications.MobileNetV2(include_top=False,\n",
    "                                                            weights='imagenet',\n",
    "                                                            input_shape=(160,160,3),\n",
    "                                                            pooling='max')\n",
    "    transfer_layer = pretrained_model\n",
    "    return transfer_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-snake",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3e7f27ed98782c9c580167c74381106",
     "grade": false,
     "grade_id": "cell-a8c7942d17cfed4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "efficient_net_b1_body = get_ENB1_body()\n",
    "efficient_net_b1_body.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-cosmetic",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0199010fb72185b3e8a9970bd8411c63",
     "grade": false,
     "grade_id": "cell-dd46ca4531e3c792",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transfered_model(pretrained_model):\n",
    "    model = Sequential()\n",
    "    model.add(pretrained_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-photograph",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7c9ba248e723747252c9d409b41a076",
     "grade": false,
     "grade_id": "cell-8371bce84e5ed677",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tran_model = transfered_model(efficient_net_b1_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-philosophy",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c490728f45aeda6811ff599dfc911b3",
     "grade": false,
     "grade_id": "cell-862289f55a2855eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tran_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free ENB1 weights\n",
    "tran_model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-woman",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "233341af286aa5f5371aad925ad43104",
     "grade": false,
     "grade_id": "cell-fbf20d166e9b45e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# resize image to the input of ENB1\n",
    "def preprocess_for_transfer(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    image = tf.image.resize_with_pad(image, 160, 160)\n",
    "    return image, label\n",
    "\n",
    "def create_transfer_dataset(x,y):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    dataset = dataset.map(preprocess_for_transfer)\n",
    "    dataset = dataset.batch(128)\n",
    "    dataset = dataset.prefetch(256)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-david",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f712c4c1921ef5f7b9772a21ac9fa9fb",
     "grade": false,
     "grade_id": "cell-3992b6ca1adb7366",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "train_dataset_resized = create_transfer_dataset(x_train, y_train)\n",
    "test_dataset_resized = create_transfer_dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-recognition",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c8dd52dd77ed40e9ba642c39e6d1677",
     "grade": false,
     "grade_id": "cell-c2702ac797ba4ad8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "compile_model(tran_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-denial",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6104d71a6ee2c287d94198e6a9781da3",
     "grade": false,
     "grade_id": "cell-e0e2ad818595f1d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "early_stop = EarlyStopping(patience=4, monitor='val_accuracy')\n",
    "tran_history = tran_model.fit(train_dataset_resized, epochs=30, validation_data=test_dataset_resized, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-valuation",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "852ea376e9cc28a09272d20dda78d02a",
     "grade": false,
     "grade_id": "cell-32893ad0dcfed252",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tran_history.history)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-huntington",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d566ec4c00c547d44a98b648438d8d3f",
     "grade": false,
     "grade_id": "cell-9df6d2cfead61763",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot loss and accuracy against epoch\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8,3.5))\n",
    "df.plot(y=['loss', 'val_loss'], ax=axes[0], title='loss vs epcoh')\n",
    "df.plot(y=['accuracy', 'val_accuracy'], ax=axes[1], title='accuracy vs epoch')\n",
    "axes[0].set_xlabel('epoch')\n",
    "axes[0].set_ylabel('loss')\n",
    "axes[1].set_xlabel('epoch')\n",
    "axes[1].set_ylabel('accuracy')\n",
    "plt.subplots_adjust(wspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-soviet",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c5d32b3439891e1d6c157d09945aa03",
     "grade": false,
     "grade_id": "cell-1e190e1523002543",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the model on the test set\n",
    "tran_model.evaluate(test_dataset_resized, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-tanzania",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "754d5d225c07ff097edb896ff3badc37",
     "grade": false,
     "grade_id": "cell-3058f1a327bdb630",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "By using transfer learning, we pushed the accuracy to over 70%! Note that now the state of the art benchmark accuracy on this task is [99.70%](https://paperswithcode.com/sota/image-classification-on-cifar-10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-ability",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9895da88de1bb4395943f0f07ee6aa4",
     "grade": false,
     "grade_id": "cell-461fb842f147ac03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a name='da'></a>\n",
    "# Graded Function\n",
    "## Data Augmentation\n",
    "Complete the create_image_generator function below. You should:\n",
    "* create an ImageDataGenerator instance\n",
    "* initialize the ImageDataGenerator instance with: horizontal_flip=True, vertical_flip=True, rotation_range=180, rescale=1/255.0\n",
    "* return this ImageDataGenerator instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-symbol",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1944e4911cea04271c358cfde48bd1b",
     "grade": false,
     "grade_id": "cell-e8f73c60d2d5dab5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def create_image_generator():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-student",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91df5d9ad238d1f0b3121cb4598fa700",
     "grade": true,
     "grade_id": "cell-da6fe67350d78f3d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell contains a hiddent test, don't delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = create_image_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-samba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "871dfe789c95e4c4e00da4a978c4fb41",
     "grade": false,
     "grade_id": "cell-383223f3264ad4fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first train images and their augmented iamges\n",
    "classes = [\"airplane\",\"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "          \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "fig, axs = plt.subplots(1,5, figsize=(15,15))\n",
    "for i in range(5):\n",
    "    if i == 0:\n",
    "        axs[i].imshow(x_train[i])\n",
    "    else:\n",
    "         axs[i].imshow(img_gen.random_transform(x_train[0]))\n",
    "    axs[i].set_title(classes[y_train[0][0]])\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-kingston",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17ff091830e3066344f3e0b71721a0f8",
     "grade": false,
     "grade_id": "cell-6198cc6cfafde568",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Try to play with data augmentation and use it to improve our classification model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-senator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
